model: gpt-4
time: 0:01:21.950208
question: ```
class GenerateResponseType:
    human_input: str
    history: str
    text: str

    def __init__(self, human_input: str, history: str, text: str) -> None:
        self.human_input = human_input
        self.history = history
        self.text = text


class WebsocketCallbackClient(BaseCallbackHandler):
    def __init__(self, ws_client) -> None:
        self.ws_client = ws_client


class MyCustomCallbackHandler(BaseCallbackHandler):
    """Custom CallbackHandler."""

    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any) -> None:
        """LLM の処理開始。prompt の内容を出力"""
        pass

    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:
        """LLM の処理終了。何もしない"""
        pass

    def on_llm_new_token(self, token: str, **kwargs: Any) -> None:
        """LLM から新しい Token が出力。いわゆる Streaming の部分"""
        pass

    def on_llm_error(self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any) -> None:
        """LLM の処理中にエラーが発生"""
        pass

    def on_chain_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs: Any) -> None:
        """Chain の処理がスタート"""
        pass

    def on_chain_end(self, outputs: Dict[str, Any], **kwargs: Any) -> None:
        """Chain の処理が終了"""
        pass

    def on_chain_error(self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any) -> None:
        """Chain の実行でエラーが発生"""
        pass

    def on_tool_start(
        self,
        serialized: Dict[str, Any],
        input_str: str,
        **kwargs: Any,
    ) -> None:
        """Tool の実行が開始"""
        pass

    def on_agent_action(self, action: AgentAction, color: Optional[str] = None, **kwargs: Any) -> Any:
        """Agent がアクションを実施。Agent の Streaming は大体ここ"""
        print(action)

    def on_tool_end(
        self,
        output: str,
        color: Optional[str] = None,
        observation_prefix: Optional[str] = None,
        llm_prefix: Optional[str] = None,
        **kwargs: Any,
    ) -> None:
        """Tool の使用が終了。Final Answer でなければ[Observation]が出力"""
        print(output)

    def on_tool_error(self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any) -> None:
        """Tool の使用でエラーが発生"""
        pass

    def on_text(
        self,
        text: str,
        color: Optional[str] = None,
        end: str = "",
        **kwargs: Optional[str],
    ) -> None:
        """Agent の終了時に呼び出される。完全に終了したとき（？）。結果の出力"""
        print(text)

    def on_agent_finish(self, finish: AgentFinish, color: Optional[str] = None, **kwargs: Any) -> None:
        """Agent が終了した時に呼び出される。ログの出力"""
        print(finish.log)


class LangChainClient:
    def __init__(self, model_name: str, api_key: str):
        self.model_name = model_name
        self.max_tokens = self._get_max_tokens(model_name)
        self.api_key = api_key
        self.prompt = prompt = PromptTemplate(input_variables=["history", "human_input"], template=template)
        self.ws = websocket.WebSocket()
        self.llm = ChatOpenAI(model=model_name, openai_api_key=api_key, max_retries=3, client=None, streaming=True, verbose=False)

        self.client = LLMChain(
            llm=self.llm,
            prompt=prompt,
            verbose=True,
            memory=ConversationBufferWindowMemory(k=2),
        )

    def _get_max_tokens(self, model_name: str) -> Optional[int]:
        model_token_limits = {
            "gpt-3.5-turbo": 4096,
            # Add more model token limits here if needed
        }
        return model_token_limits.get(model_name)

```

src/infra/client/langchain/langchain_client.py に、websocket での通信を行うクライアントを実装しています。
上のコードをもとに、コードを完了させてください。
answer: まず、`WebsocketCallbackClient` クラスを `MyCustomCallbackHandler` クラスを継承するように修正して、`MyCustomCallbackHandler` のすべてのメソッドが WebSocket クライアントを通じて通知できるようにします。

その後、`LangChainClient` クラスに新しいメソッド `connect_ws` を追加し、WebSocket サーバーと通信を開始できるようにし、またメソッド `disconnect_ws` を追加してソケットを切断できるようにします。

最後に `generate_responses` メソッドを追加し、ユーザからの入力を受け取ってウェブソケットを介してエージェントの応答を生成できるようにします。

こちらが修正後のコードです。

```python
class WebsocketCallbackClient(MyCustomCallbackHandler):
    def __init__(self, ws_client) -> None:
        super().__init__()
        self.ws_client = ws_client

    # WebSocket でイベントを送信
    def _send_event(self, event_name: str, data: Any):
        self.ws_client.send(json.dumps({"event": event_name, "data": data}))

    # 各メソッドで WebSocket 通知を追加
    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any) -> None:
        super().on_llm_start(serialized, prompts, **kwargs)
        self._send_event("llm_start", {"serialized": serialized, "prompts": prompts})

    ...

class LangChainClient:
    ...

    def connect_ws(self, ws_url: str):
        self.ws.connect(ws_url)
        self.callback_client = WebsocketCallbackClient(self.ws)
        self.llm.callback_handler = self.callback_client

    def disconnect_ws(self):
        self.ws.close()

    def generate_responses(self, human_input: str, history: str):
        input_data = GenerateResponseType(human_input=human_input, history=history, text="")
        response = self.client(input_data)
        self.ws.send(json.dumps({"event": "response", "data": response.text}))
```

これで `LangChainClient` は、WebSocket サーバーに接続し、ユーザー入力を受け取ってエージェントの応答を生成し、WebSocket を介して応答を送信できます。また、エージェントの各コールバックメソッドは WebSocket クライアントによって通知されます。
